{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVES BAYES - Utillisation de MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"not_sexist\", \"sexist\"]\n",
    "    #               2161           989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"my_csv_clean.csv\",sep = ',')\n",
    "data.columns = ['tweet', 'class']\n",
    "\n",
    "X = data['tweet']\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X , y ,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tokenisation avec scikit-learrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 8637)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Des occurences aux fréquences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 8637)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Construction du model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tests sur des exemples simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'La femme doit être dans la cuisine' => not_sexist\n",
      "'La femme est belle' => sexist\n",
      "'Un homme' => not_sexist\n",
      "'Les hommes sont tous les mêmes' => not_sexist\n"
     ]
    }
   ],
   "source": [
    "tweet_test = ['La femme doit être dans la cuisine', \"La femme est belle\", \"Un homme\", \"Les hommes sont tous les mêmes\"]\n",
    "X_new_counts = count_vect.transform(tweet_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(tweet_test, predicted):\n",
    "     print('%r => %s' % (doc, categories[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test sur X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[653   3]\n",
      " [264  25]]\n",
      "Accuracy :  0.7174603174603175\n",
      "Balanced accuracy 0.5409660097898557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not_sexist       0.71      1.00      0.83       656\n",
      "      sexist       0.89      0.09      0.16       289\n",
      "\n",
      "    accuracy                           0.72       945\n",
      "   macro avg       0.80      0.54      0.49       945\n",
      "weighted avg       0.77      0.72      0.62       945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_new_counts =  count_vect.transform(X_test)\n",
    "X_test_new_tfidf = tfidf_transformer.transform(X_test_new_counts)\n",
    "predicted = clf.predict(X_test_new_tfidf)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(\"Accuracy : \", np.mean(predicted == y_test))\n",
    "print(\"Balanced accuracy\", metrics.balanced_accuracy_score(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1503, 0: 1503})\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_resample(np.array(X_train).reshape(-1,1), y_train)\n",
    "print(Counter(y_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3006, 8637)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_ros.ravel())\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3006, 8637)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"y'a que les femmes qui pleurent\" => sexist\n",
      "\"C'est un homme.\" => sexist\n",
      "\n",
      "Accuracy :  0.7469512195121951\n",
      "\n",
      "Matrice de confusion : \n",
      "[[456 200]\n",
      " [132 524]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not_sexist       0.78      0.70      0.73       656\n",
      "      sexist       0.72      0.80      0.76       656\n",
      "\n",
      "    accuracy                           0.75      1312\n",
      "   macro avg       0.75      0.75      0.75      1312\n",
      "weighted avg       0.75      0.75      0.75      1312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_ros)\n",
    "docs_new = [\"y'a que les femmes qui pleurent\", \"C'est un homme.\"] \n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "     print('%r => %s' % (doc, categories[category]))\n",
    "        \n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()),])\n",
    "text_clf.fit(X_ros.ravel(), y_ros)\n",
    "\n",
    "\n",
    "# resampling X, y\n",
    "X_ros_test, y_ros_test = ros.fit_resample(np.array(X_test).reshape(-1,1), y_test)# new class distribution \n",
    "docs_test = X_ros_test.ravel()\n",
    "predicted = text_clf.predict(docs_test)\n",
    "print()\n",
    "print(\"Accuracy : \", np.mean(predicted == y_ros_test))\n",
    "print()\n",
    "print(\"Matrice de confusion : \")\n",
    "print(metrics.confusion_matrix(y_ros_test, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_ros_test, predicted,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 700, 1: 700})\n"
     ]
    }
   ],
   "source": [
    "# instantiating the random over sampler \n",
    "rus = RandomUnderSampler()\n",
    "# resampling X, y\n",
    "X_rus, y_rus = rus.fit_resample(np.array(X_train).reshape(-1,1), y_train)# new class distribution \n",
    "print(Counter(y_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 6496)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_rus.ravel())\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 6496)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"y'a que les femmes qui pleurent\" => sexist\n",
      "\"C'est un homme.\" => sexist\n",
      "\n",
      "Accuracy :  0.7422145328719724\n",
      "\n",
      "Matrice de confusion : \n",
      "[[182 107]\n",
      " [ 42 247]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not_sexist       0.81      0.63      0.71       289\n",
      "      sexist       0.70      0.85      0.77       289\n",
      "\n",
      "    accuracy                           0.74       578\n",
      "   macro avg       0.76      0.74      0.74       578\n",
      "weighted avg       0.76      0.74      0.74       578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_rus)\n",
    "docs_new = [\"y'a que les femmes qui pleurent\", \"C'est un homme.\"] \n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "     print('%r => %s' % (doc, categories[category]))\n",
    "        \n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()),])\n",
    "text_clf.fit(X_rus.ravel(), y_rus)\n",
    "\n",
    "\n",
    "# resampling X, y\n",
    "X_rus_test, y_rus_test = rus.fit_resample(np.array(X_test).reshape(-1,1), y_test)# new class distribution \n",
    "docs_test = X_rus_test.ravel()\n",
    "predicted = text_clf.predict(docs_test)\n",
    "print()\n",
    "print(\"Accuracy : \", np.mean(predicted == y_rus_test))\n",
    "print()\n",
    "print(\"Matrice de confusion : \")\n",
    "print(metrics.confusion_matrix(y_rus_test, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_rus_test, predicted,target_names=categories))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Oversampling and Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(sampling_strategy=0.5)\n",
    "under = RandomUnderSampler(sampling_strategy=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled: Counter({0: 1503, 1: 751})\n"
     ]
    }
   ],
   "source": [
    "X_over, y_over = over.fit_resample(np.array(X_train).reshape(-1,1), y_train)\n",
    "print(f\"Oversampled: {Counter(y_over)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Random Sampling: Counter({0: 938, 1: 751})\n"
     ]
    }
   ],
   "source": [
    "# now to comine under sampling \n",
    "X_ros, y_ros = under.fit_resample(X_over, y_over)\n",
    "print(f\"Combined Random Sampling: {Counter(y_ros)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1689, 7188)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_ros.ravel())\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1689, 7188)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"y'a que les femmes qui pleurent\" => sexist\n",
      "\"C'est un homme.\" => sexist\n",
      "Accuracy :  0.7591463414634146\n",
      "Matrice de confusion : \n",
      "[[520 136]\n",
      " [180 476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not_sexist       0.74      0.79      0.77       656\n",
      "      sexist       0.78      0.73      0.75       656\n",
      "\n",
      "    accuracy                           0.76      1312\n",
      "   macro avg       0.76      0.76      0.76      1312\n",
      "weighted avg       0.76      0.76      0.76      1312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_ros)\n",
    "docs_new = [\"y'a que les femmes qui pleurent\", \"C'est un homme.\"]\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "     print('%r => %s' % (doc, categories[category]))\n",
    "        \n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()),])\n",
    "text_clf.fit(X_ros.ravel(), y_ros)\n",
    "\n",
    "X_ros_test, y_ros_test = ros.fit_resample(np.array(X_test).reshape(-1,1), y_test)# new class distribution \n",
    "docs_test = X_ros_test.ravel()\n",
    "predicted = text_clf.predict(docs_test)\n",
    "print(\"Accuracy : \", np.mean(predicted == y_ros_test))\n",
    "print(\"Matrice de confusion : \")\n",
    "print(metrics.confusion_matrix(y_ros_test, predicted))\n",
    "print(metrics.classification_report(y_ros_test, predicted,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES - Approche manuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evara\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(\"my_csv_clean.csv\",sep = ',') #we got that csv after running the Text Preprocessing file\n",
    "data.columns = ['tweet', 'class']\n",
    "    \n",
    "\n",
    "X = data['tweet']\n",
    "y = data['class'] \n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X , y ,test_size=0.3)\n",
    "\n",
    "\n",
    "categories = [\"NotSexist\", \"Sexist\"]\n",
    "\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "X_train_0 = []\n",
    "X_train_1 = []\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==0:\n",
    "        X_train_0.append(X_train[i])\n",
    "    else:\n",
    "        X_train_1.append(X_train[i])\n",
    "\n",
    "vec_train_0 = CountVectorizer()\n",
    "X_c0 = vec_train_0.fit_transform(X_train_0)\n",
    "tdm_0 = pd.DataFrame(X_c0.toarray(), columns=vec_train_0.get_feature_names())\n",
    "\n",
    "\n",
    "vec_train_1 = CountVectorizer()\n",
    "X_c1 = vec_train_1.fit_transform(X_train_1)\n",
    "tdm_1 = pd.DataFrame(X_c1.toarray(), columns=vec_train_1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_0 = vec_train_0.get_feature_names();    \n",
    "count_list_0 = X_c0.toarray().sum(axis=0) \n",
    "freq_0 = dict(zip(word_list_0,count_list_0))\n",
    "\n",
    "word_list_1 = vec_train_1.get_feature_names();    \n",
    "count_list_1 = X_c1.toarray().sum(axis=0) \n",
    "freq_1 = dict(zip(word_list_1,count_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_0 = []\n",
    "for word,count in zip(word_list_0,count_list_0):\n",
    "    prob_0.append(count/len(word_list_0))\n",
    "    \n",
    "prob_1 = []\n",
    "for word,count in zip(word_list_1,count_list_1):\n",
    "    prob_1.append(count/len(word_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6521"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_0 = CountVectorizer()\n",
    "X_vec_0 = vec_0.fit_transform(X_train_0)\n",
    "\n",
    "total_features0 = len(vec_0.get_feature_names())\n",
    "total_features0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6200437387087573\n",
      "0.37995626129124277\n"
     ]
    }
   ],
   "source": [
    "vec_1 = CountVectorizer()\n",
    "X_vec_1 = vec_1.fit_transform(X_train_1)\n",
    "total_features1 = len(vec_1.get_feature_names())\n",
    "total_features1\n",
    "\n",
    "proba0 = total_features0 / (total_features0+total_features1)\n",
    "proba1 = total_features1 / (total_features0+total_features1)\n",
    "\n",
    "print(proba0)\n",
    "print(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_0 = count_list_0.sum(axis=0)\n",
    "total_cnts_features_1 = count_list_1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def proba_sentence_class0(sentence, total_cnts_features, total_features):\n",
    "    new_word_list = word_tokenize(sentence)\n",
    "    prob_s_with_ls = []\n",
    "    for word in new_word_list:\n",
    "        if word in freq_0.keys():\n",
    "            count = freq_0[word]\n",
    "        else:\n",
    "            count = 0\n",
    "        prob_s_with_ls.append((count + 1)/(total_cnts_features + total_features))\n",
    "    d = dict(zip(new_word_list,prob_s_with_ls))\n",
    "    res = 1\n",
    "    for word in sentence.split():\n",
    "        res = res * d[word]\n",
    "\n",
    "    res = res * proba0\n",
    "    return res\n",
    "\n",
    "def proba_sentence_class1(sentence,total_cnts_features, total_features):\n",
    "    new_word_list = word_tokenize(sentence)\n",
    "    prob_s_with_ls = []\n",
    "    for word in new_word_list:\n",
    "        if word in freq_1.keys():\n",
    "            count = freq_1[word]\n",
    "        else:\n",
    "            count = 0\n",
    "        prob_s_with_ls.append((count + 1)/(total_cnts_features + total_features))\n",
    "    d = dict(zip(new_word_list,prob_s_with_ls))\n",
    "    res = 1\n",
    "    for word in sentence.split():\n",
    "        res = res * d[word]\n",
    "\n",
    "    res = res * proba1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in X_test:\n",
    "    proba_class0 = proba_sentence_class0(i,total_cnts_features_0,total_features0)\n",
    "    proba_class1 = proba_sentence_class1(i,total_cnts_features_1,total_features1)\n",
    "    if proba_class0 > proba_class1:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6402116402116402\n",
      "\n",
      "Balanced accuracy : 0.7217465753424658\n",
      "\n",
      "Matrice de confusion :\n",
      "[[337 320]\n",
      " [ 20 268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NotSexist       0.94      0.51      0.66       657\n",
      "      Sexist       0.46      0.93      0.61       288\n",
      "\n",
      "    accuracy                           0.64       945\n",
      "   macro avg       0.70      0.72      0.64       945\n",
      "weighted avg       0.80      0.64      0.65       945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_labels = len(y_test)\n",
    "acc = 0\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i]==predictions[i]):\n",
    "        acc = acc + 1\n",
    "        \n",
    "acc = acc / total_labels\n",
    "print(\"Accuracy :\" , acc)\n",
    "print()\n",
    "print(\"Balanced accuracy :\" , metrics.balanced_accuracy_score(y_test, predictions))\n",
    "print()\n",
    "print(\"Matrice de confusion :\")\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "print(metrics.classification_report(y_test, predictions,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES - Approche manuelle + Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evara\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(\"my_csv_clean.csv\",sep = ',')\n",
    "data.columns = ['tweet', 'class']\n",
    "    \n",
    "\n",
    "X = data['tweet']\n",
    "y = data['class'] \n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X , y ,test_size=0.3)\n",
    "\n",
    "\n",
    "categories = [\"NotSexist\", \"Sexist\"]\n",
    "\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "X_ros_train, y_ros_train = ros.fit_resample(np.array(X_train).reshape(-1,1), y_train)\n",
    "X_ros_test, y_ros_test = ros.fit_resample(np.array(X_test).reshape(-1,1), y_test)\n",
    "\n",
    "\n",
    "X_train_0 = []\n",
    "X_train_1 = []\n",
    "\n",
    "for i in range(len(y_ros_train)):\n",
    "    if y_ros_train[i]==0:\n",
    "        X_train_0.append(X_ros_train[i].tolist()[0])\n",
    "    else:\n",
    "        X_train_1.append(X_ros_train[i].tolist()[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vec_train_0 = CountVectorizer()\n",
    "X_c0 = vec_train_0.fit_transform(X_train_0)\n",
    "tdm_0 = pd.DataFrame(X_c0.toarray(), columns=vec_train_0.get_feature_names())\n",
    "\n",
    "\n",
    "vec_train_1 = CountVectorizer()\n",
    "X_c1 = vec_train_1.fit_transform(X_train_1)\n",
    "tdm_1 = pd.DataFrame(X_c1.toarray(), columns=vec_train_1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_0 = vec_train_0.get_feature_names();    \n",
    "count_list_0 = X_c0.toarray().sum(axis=0) \n",
    "freq_0 = dict(zip(word_list_0,count_list_0))\n",
    "\n",
    "word_list_1 = vec_train_1.get_feature_names();    \n",
    "count_list_1 = X_c1.toarray().sum(axis=0) \n",
    "freq_1 = dict(zip(word_list_1,count_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_0 = []\n",
    "for word,count in zip(word_list_0,count_list_0):\n",
    "    prob_0.append(count/len(word_list_0))\n",
    "    \n",
    "prob_1 = []\n",
    "for word,count in zip(word_list_1,count_list_1):\n",
    "    prob_1.append(count/len(word_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6606"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_0 = CountVectorizer()\n",
    "X_vec_0 = vec_0.fit_transform(X_train_0)\n",
    "\n",
    "total_features0 = len(vec_0.get_feature_names())\n",
    "total_features0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6222096637468212\n",
      "0.37779033625317887\n"
     ]
    }
   ],
   "source": [
    "vec_1 = CountVectorizer()\n",
    "X_vec_1 = vec_1.fit_transform(X_train_1)\n",
    "total_features1 = len(vec_1.get_feature_names())\n",
    "total_features1\n",
    "\n",
    "proba0 = total_features0 / (total_features0+total_features1)\n",
    "proba1 = total_features1 / (total_features0+total_features1)\n",
    "\n",
    "print(proba0)\n",
    "print(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_0 = count_list_0.sum(axis=0)\n",
    "total_cnts_features_1 = count_list_1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in X_ros_test:\n",
    "    proba_class0 = proba_sentence_class0(i[0],total_cnts_features_0,total_features0)\n",
    "    proba_class1 = proba_sentence_class1(i[0],total_cnts_features_1,total_features1)\n",
    "    if proba_class0 > proba_class1:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7697674418604651\n",
      "\n",
      "Matrice de confusion :\n",
      "[[445 200]\n",
      " [ 97 548]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NotSexist       0.82      0.69      0.75       645\n",
      "      Sexist       0.73      0.85      0.79       645\n",
      "\n",
      "    accuracy                           0.77      1290\n",
      "   macro avg       0.78      0.77      0.77      1290\n",
      "weighted avg       0.78      0.77      0.77      1290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_labels = len(y_ros_test)\n",
    "acc = 0\n",
    "for i in range(len(y_ros_test)):\n",
    "    if(y_ros_test[i]==predictions[i]):\n",
    "        acc = acc + 1\n",
    "        \n",
    "acc = acc / total_labels\n",
    "print(\"Accuracy :\" , acc)\n",
    "print()\n",
    "print(\"Matrice de confusion :\")\n",
    "print(metrics.confusion_matrix(y_ros_test, predictions))\n",
    "print(metrics.classification_report(y_ros_test, predictions,target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES - Approche manuelle + Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evara\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(\"my_csv_clean.csv\",sep = ',') #we got that csv after running the Text Preprocessing file\n",
    "data.columns = ['tweet', 'class']\n",
    "    \n",
    "\n",
    "X = data['tweet']\n",
    "y = data['class'] \n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X , y ,test_size=0.3)\n",
    "\n",
    "\n",
    "categories = [\"NotSexist\", \"Sexist\"]\n",
    "\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_rus_train, y_rus_train = rus.fit_resample(np.array(X_train).reshape(-1,1), y_train)# new class distribution \n",
    "X_rus_test, y_rus_test = rus.fit_resample(np.array(X_test).reshape(-1,1), y_test)# new class distribution \n",
    "\n",
    "\n",
    "X_train_0 = []\n",
    "X_train_1 = []\n",
    "\n",
    "for i in range(len(y_rus_train)):\n",
    "    if y_rus_train[i]==0:\n",
    "        X_train_0.append(X_rus_train[i].tolist()[0])\n",
    "    else:\n",
    "        X_train_1.append(X_rus_train[i].tolist()[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vec_train_0 = CountVectorizer()\n",
    "X_c0 = vec_train_0.fit_transform(X_train_0)\n",
    "tdm_0 = pd.DataFrame(X_c0.toarray(), columns=vec_train_0.get_feature_names())\n",
    "\n",
    "\n",
    "vec_train_1 = CountVectorizer()\n",
    "X_c1 = vec_train_1.fit_transform(X_train_1)\n",
    "tdm_1 = pd.DataFrame(X_c1.toarray(), columns=vec_train_1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_0 = vec_train_0.get_feature_names();    \n",
    "count_list_0 = X_c0.toarray().sum(axis=0) \n",
    "freq_0 = dict(zip(word_list_0,count_list_0))\n",
    "\n",
    "word_list_1 = vec_train_1.get_feature_names();    \n",
    "count_list_1 = X_c1.toarray().sum(axis=0) \n",
    "freq_1 = dict(zip(word_list_1,count_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_0 = []\n",
    "for word,count in zip(word_list_0,count_list_0):\n",
    "    prob_0.append(count/len(word_list_0))\n",
    "    \n",
    "prob_1 = []\n",
    "for word,count in zip(word_list_1,count_list_1):\n",
    "    prob_1.append(count/len(word_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3862"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_0 = CountVectorizer()\n",
    "X_vec_0 = vec_0.fit_transform(X_train_0)\n",
    "\n",
    "total_features0 = len(vec_0.get_feature_names())\n",
    "total_features0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49360940695296524\n",
      "0.5063905930470347\n"
     ]
    }
   ],
   "source": [
    "vec_1 = CountVectorizer()\n",
    "X_vec_1 = vec_1.fit_transform(X_train_1)\n",
    "total_features1 = len(vec_1.get_feature_names())\n",
    "total_features1\n",
    "\n",
    "proba0 = total_features0 / (total_features0+total_features1)\n",
    "proba1 = total_features1 / (total_features0+total_features1)\n",
    "\n",
    "print(proba0)\n",
    "print(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_0 = count_list_0.sum(axis=0)\n",
    "total_cnts_features_1 = count_list_1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in X_rus_test:\n",
    "    proba_class0 = proba_sentence_class0(i[0],total_cnts_features_0,total_features0)\n",
    "    proba_class1 = proba_sentence_class1(i[0],total_cnts_features_1,total_features1)\n",
    "    if proba_class0 > proba_class1:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7298657718120806\n",
      "\n",
      "Matrice de confusion :\n",
      "[[202  96]\n",
      " [ 65 233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NotSexist       0.76      0.68      0.72       298\n",
      "      Sexist       0.71      0.78      0.74       298\n",
      "\n",
      "    accuracy                           0.73       596\n",
      "   macro avg       0.73      0.73      0.73       596\n",
      "weighted avg       0.73      0.73      0.73       596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_labels = len(y_rus_test)\n",
    "acc = 0\n",
    "for i in range(len(y_rus_test)):\n",
    "    if(y_rus_test[i]==predictions[i]):\n",
    "        acc = acc + 1\n",
    "        \n",
    "acc = acc / total_labels\n",
    "print(\"Accuracy :\" , acc)\n",
    "print()\n",
    "print(\"Matrice de confusion :\")\n",
    "print(metrics.confusion_matrix(y_rus_test, predictions))\n",
    "print(metrics.classification_report(y_rus_test, predictions,target_names=categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
