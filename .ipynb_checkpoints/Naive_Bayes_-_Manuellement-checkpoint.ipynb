{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVES BAYES - Utillisation de MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"not_sexist\", \"sexist\"]\n",
    "    #               2161           989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"my_csv_clean.csv\",sep = ',')\n",
    "data.columns = ['tweet', 'class']\n",
    "\n",
    "X = data['tweet']\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X , y ,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ff645c1f7da4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcount_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES - Approche manuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evara\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(\"my_csv_clean.csv\",sep = ',') #we got that csv after running the Text Preprocessing file\n",
    "data.columns = ['tweet', 'class']\n",
    "    \n",
    "\n",
    "X = data['tweet']\n",
    "y = data['class'] \n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X , y ,test_size=0.3)\n",
    "\n",
    "\n",
    "categories = [\"NotSexist\", \"Sexist\"]\n",
    "\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "X_train_0 = []\n",
    "X_train_1 = []\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==0:\n",
    "        X_train_0.append(X_train[i])\n",
    "    else:\n",
    "        X_train_1.append(X_train[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vec_train_0 = CountVectorizer()\n",
    "X_c0 = vec_0.fit_transform(X_train_0)\n",
    "tdm_0 = pd.DataFrame(X_c0.toarray(), columns=vec_0.get_feature_names())\n",
    "\n",
    "\n",
    "vec__train_1 = CountVectorizer()\n",
    "X_c1 = vec_1.fit_transform(X_train_1)\n",
    "tdm_1 = pd.DataFrame(X_c1.toarray(), columns=vec_1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_0 = vec_0.get_feature_names();    \n",
    "count_list_0 = X_c0.toarray().sum(axis=0) \n",
    "freq_0 = dict(zip(word_list_0,count_list_0))\n",
    "\n",
    "word_list_1 = vec_1.get_feature_names();    \n",
    "count_list_1 = X_c1.toarray().sum(axis=0) \n",
    "freq_1 = dict(zip(word_list_1,count_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_0 = []\n",
    "for word,count in zip(word_list_0,count_list_0):\n",
    "    prob_0.append(count/len(word_list_0))\n",
    "    \n",
    "prob_1 = []\n",
    "for word,count in zip(word_list_1,count_list_1):\n",
    "    prob_1.append(count/len(word_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7185"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_0 = CountVectorizer()\n",
    "X_vec_0 = vec_0.fit_transform(X_train_0)\n",
    "\n",
    "total_features0 = len(vec_0.get_feature_names())\n",
    "total_features0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6197170950491634\n",
      "0.38028290495083666\n"
     ]
    }
   ],
   "source": [
    "vec_1 = CountVectorizer()\n",
    "X_vec_1 = vec_1.fit_transform(X_train_1)\n",
    "total_features1 = len(vec_1.get_feature_names())\n",
    "total_features1\n",
    "\n",
    "proba0 = total_features0 / (total_features0+total_features1)\n",
    "proba1 = total_features1 / (total_features0+total_features1)\n",
    "\n",
    "print(proba0)\n",
    "print(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_0 = count_list_0.sum(axis=0)\n",
    "total_cnts_features_1 = count_list_1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def proba_sentence_class0(sentence, total_cnts_features, total_features):\n",
    "    new_word_list = word_tokenize(sentence)\n",
    "    prob_s_with_ls = []\n",
    "    for word in new_word_list:\n",
    "        if word in freq_0.keys():\n",
    "            count = freq_0[word]\n",
    "        else:\n",
    "            count = 0\n",
    "        prob_s_with_ls.append((count + 1)/(total_cnts_features + total_features))\n",
    "    d = dict(zip(new_word_list,prob_s_with_ls))\n",
    "    res = 1\n",
    "    for word in sentence.split():\n",
    "        res = res * d[word]\n",
    "\n",
    "    res = res * proba0\n",
    "    return res\n",
    "\n",
    "def proba_sentence_class1(sentence,total_cnts_features, total_features):\n",
    "    new_word_list = word_tokenize(sentence)\n",
    "    prob_s_with_ls = []\n",
    "    for word in new_word_list:\n",
    "        if word in freq_1.keys():\n",
    "            count = freq_1[word]\n",
    "        else:\n",
    "            count = 0\n",
    "        prob_s_with_ls.append((count + 1)/(total_cnts_features + total_features))\n",
    "    d = dict(zip(new_word_list,prob_s_with_ls))\n",
    "    res = 1\n",
    "    for word in sentence.split():\n",
    "        res = res * d[word]\n",
    "\n",
    "    res = res * proba1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in X_test:\n",
    "    proba_class0 = proba_sentence_class0(i,total_cnts_features_0,total_features0)\n",
    "    proba_class1 = proba_sentence_class1(i,total_cnts_features_1,total_features1)\n",
    "    if proba_class0 > proba_class1:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.656084656084656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[352, 310],\n",
       "       [ 15, 268]], dtype=int64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels = len(y_test)\n",
    "acc = 0\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i]==predictions[i]):\n",
    "        acc = acc + 1\n",
    "        \n",
    "acc = acc / total_labels\n",
    "print(\"Accuracy :\" , acc)\n",
    "        \n",
    "metrics.confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES + OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evara\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(\"my_csv_clean.csv\",sep = ',') #we got that csv after running the Text Preprocessing file\n",
    "data.columns = ['tweet', 'class']\n",
    "    \n",
    "\n",
    "X = data['tweet']\n",
    "y = data['class'] \n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X , y ,test_size=0.3)\n",
    "\n",
    "\n",
    "categories = [\"NotSexist\", \"Sexist\"]\n",
    "\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "X_ros_train, y_ros_train = ros.fit_resample(np.array(X_train).reshape(-1,1), y_train)# new class distribution \n",
    "X_ros_test, y_ros_test = ros.fit_resample(np.array(X_test).reshape(-1,1), y_test)# new class distribution \n",
    "\n",
    "\n",
    "X_train_0 = []\n",
    "X_train_1 = []\n",
    "\n",
    "for i in range(len(y_ros_train)):\n",
    "    if y_ros_train[i]==0:\n",
    "        X_train_0.append(X_ros_train[i].tolist()[0])\n",
    "    else:\n",
    "        X_train_1.append(X_ros_train[i].tolist()[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vec_train_0 = CountVectorizer()\n",
    "X_c0 = vec_0.fit_transform(X_train_0)\n",
    "tdm_0 = pd.DataFrame(X_c0.toarray(), columns=vec_0.get_feature_names())\n",
    "\n",
    "\n",
    "vec__train_1 = CountVectorizer()\n",
    "X_c1 = vec_1.fit_transform(X_train_1)\n",
    "tdm_1 = pd.DataFrame(X_c1.toarray(), columns=vec_1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_0 = vec_0.get_feature_names();    \n",
    "count_list_0 = X_c0.toarray().sum(axis=0) \n",
    "freq_0 = dict(zip(word_list_0,count_list_0))\n",
    "\n",
    "word_list_1 = vec_1.get_feature_names();    \n",
    "count_list_1 = X_c1.toarray().sum(axis=0) \n",
    "freq_1 = dict(zip(word_list_1,count_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_0 = []\n",
    "for word,count in zip(word_list_0,count_list_0):\n",
    "    prob_0.append(count/len(word_list_0))\n",
    "    \n",
    "prob_1 = []\n",
    "for word,count in zip(word_list_1,count_list_1):\n",
    "    prob_1.append(count/len(word_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7293"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_0 = CountVectorizer()\n",
    "X_vec_0 = vec_0.fit_transform(X_train_0)\n",
    "\n",
    "total_features0 = len(vec_0.get_feature_names())\n",
    "total_features0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6257400257400257\n",
      "0.37425997425997426\n"
     ]
    }
   ],
   "source": [
    "vec_1 = CountVectorizer()\n",
    "X_vec_1 = vec_1.fit_transform(X_train_1)\n",
    "total_features1 = len(vec_1.get_feature_names())\n",
    "total_features1\n",
    "\n",
    "proba0 = total_features0 / (total_features0+total_features1)\n",
    "proba1 = total_features1 / (total_features0+total_features1)\n",
    "\n",
    "print(proba0)\n",
    "print(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_0 = count_list_0.sum(axis=0)\n",
    "total_cnts_features_1 = count_list_1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in X_ros_test:\n",
    "    proba_class0 = proba_sentence_class0(i[0],total_cnts_features_0,total_features0)\n",
    "    proba_class1 = proba_sentence_class1(i[0],total_cnts_features_1,total_features1)\n",
    "    if proba_class0 > proba_class1:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7492211838006231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[452, 190],\n",
       "       [132, 510]], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels = len(y_ros_test)\n",
    "acc = 0\n",
    "for i in range(len(y_ros_test)):\n",
    "    if(y_ros_test[i]==predictions[i]):\n",
    "        acc = acc + 1\n",
    "        \n",
    "acc = acc / total_labels\n",
    "print(\"Accuracy :\" , acc)\n",
    "        \n",
    "metrics.confusion_matrix(y_ros_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES + UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evara\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(\"my_csv_clean.csv\",sep = ',') #we got that csv after running the Text Preprocessing file\n",
    "data.columns = ['tweet', 'class']\n",
    "    \n",
    "\n",
    "X = data['tweet']\n",
    "y = data['class'] \n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X , y ,test_size=0.3)\n",
    "\n",
    "\n",
    "categories = [\"NotSexist\", \"Sexist\"]\n",
    "\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X_rus_train, y_rus_train = rus.fit_resample(np.array(X_train).reshape(-1,1), y_train)# new class distribution \n",
    "X_rus_test, y_rus_test = rus.fit_resample(np.array(X_test).reshape(-1,1), y_test)# new class distribution \n",
    "\n",
    "\n",
    "X_train_0 = []\n",
    "X_train_1 = []\n",
    "\n",
    "for i in range(len(y_rus_train)):\n",
    "    if y_rus_train[i]==0:\n",
    "        X_train_0.append(X_rus_train[i].tolist()[0])\n",
    "    else:\n",
    "        X_train_1.append(X_rus_train[i].tolist()[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vec_train_0 = CountVectorizer()\n",
    "X_c0 = vec_0.fit_transform(X_train_0)\n",
    "tdm_0 = pd.DataFrame(X_c0.toarray(), columns=vec_0.get_feature_names())\n",
    "\n",
    "\n",
    "vec__train_1 = CountVectorizer()\n",
    "X_c1 = vec_1.fit_transform(X_train_1)\n",
    "tdm_1 = pd.DataFrame(X_c1.toarray(), columns=vec_1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_0 = vec_0.get_feature_names();    \n",
    "count_list_0 = X_c0.toarray().sum(axis=0) \n",
    "freq_0 = dict(zip(word_list_0,count_list_0))\n",
    "\n",
    "word_list_1 = vec_1.get_feature_names();    \n",
    "count_list_1 = X_c1.toarray().sum(axis=0) \n",
    "freq_1 = dict(zip(word_list_1,count_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_0 = []\n",
    "for word,count in zip(word_list_0,count_list_0):\n",
    "    prob_0.append(count/len(word_list_0))\n",
    "    \n",
    "prob_1 = []\n",
    "for word,count in zip(word_list_1,count_list_1):\n",
    "    prob_1.append(count/len(word_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4245"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_0 = CountVectorizer()\n",
    "X_vec_0 = vec_0.fit_transform(X_train_0)\n",
    "\n",
    "total_features0 = len(vec_0.get_feature_names())\n",
    "total_features0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494524697110904\n",
      "0.505475302889096\n"
     ]
    }
   ],
   "source": [
    "vec_1 = CountVectorizer()\n",
    "X_vec_1 = vec_1.fit_transform(X_train_1)\n",
    "total_features1 = len(vec_1.get_feature_names())\n",
    "total_features1\n",
    "\n",
    "proba0 = total_features0 / (total_features0+total_features1)\n",
    "proba1 = total_features1 / (total_features0+total_features1)\n",
    "\n",
    "print(proba0)\n",
    "print(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_0 = count_list_0.sum(axis=0)\n",
    "total_cnts_features_1 = count_list_1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in X_rus_test:\n",
    "    proba_class0 = proba_sentence_class0(i[0],total_cnts_features_0,total_features0)\n",
    "    proba_class1 = proba_sentence_class1(i[0],total_cnts_features_1,total_features1)\n",
    "    if proba_class0 > proba_class1:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7483221476510067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[215,  83],\n",
       "       [ 67, 231]], dtype=int64)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels = len(y_rus_test)\n",
    "acc = 0\n",
    "for i in range(len(y_rus_test)):\n",
    "    if(y_rus_test[i]==predictions[i]):\n",
    "        acc = acc + 1\n",
    "        \n",
    "acc = acc / total_labels\n",
    "print(\"Accuracy :\" , acc)\n",
    "        \n",
    "metrics.confusion_matrix(y_rus_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
